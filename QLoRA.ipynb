{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import T5ForConditionalGeneration, T5Tokenizer\n",
    "from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n",
    "from transformers import DataCollatorForSeq2Seq, BitsAndBytesConfig\n",
    "from datasets import load_dataset\n",
    "from peft import LoraConfig, get_peft_model, TaskType, prepare_model_for_kbit_training\n",
    "from transformers import Seq2SeqTrainer, Seq2SeqTrainingArguments\n",
    "import bitsandbytes as bnb\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "import warnings\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 7473\n",
      "Evaluation set size: 1319\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'question': 'Julie is reading a 120-page book. Yesterday, she was able to read 12 pages and today, she read twice as many pages as yesterday. If she wants to read half of the remaining pages tomorrow, how many pages should she read?',\n",
       " 'answer': 'How many pages did Maila read today? ** Maila read 12 x 2 = <<12*2=24>>24 pages today.\\nHow many pages did Maila read since yesterday? ** So she was able to read a total of 12 + 24 = <<12+24=36>>36 pages since yesterday.\\nHow many pages are left to be read? ** There are 120 - 36 = <<120-36=84>>84 pages left to be read.\\nHow many pages should she read tomorrow? ** Since she wants to read half of the remaining pages tomorrow, then she should read 84/2 = <<84/2=42>>42 pages.\\n#### 42'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load GSM8K Dataset\n",
    "dataset = load_dataset(\"gsm8k\", \"socratic\")\n",
    "train = dataset[\"train\"]\n",
    "eval = dataset[\"test\"]\n",
    "print(f\"Training set size: {len(train)}\")\n",
    "print(f\"Evaluation set size: {len(eval)}\")\n",
    "display(train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define BitsAndBytesConfig for 4-bit quantization\n",
    "bnb_config = BitsAndBytesConfig(\n",
    "   load_in_4bit=True,\n",
    "   bnb_4bit_quant_type=\"nf4\",\n",
    "   bnb_4bit_compute_dtype=torch.bfloat16\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the T5-base model and tokenizer\n",
    "model_name = \"t5-base\"\n",
    "model = AutoModelForSeq2SeqLM.from_pretrained(\n",
    "    model_name,\n",
    "    quantization_config=bnb_config,\n",
    "    device_map=\"auto\",\n",
    ")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define QLoRA Configuration\n",
    "qlora_config = LoraConfig(\n",
    "    r=8,\n",
    "    lora_alpha=32,\n",
    "    lora_dropout=0.1,\n",
    "    target_modules=[\"q\", \"v\"],\n",
    "    task_type=TaskType.SEQ_2_SEQ_LM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = prepare_model_for_kbit_training(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trainable params: 884,736 || all params: 223,788,288 || trainable%: 0.3953\n"
     ]
    }
   ],
   "source": [
    "# Apply the QLoRA configuration to the model\n",
    "model = get_peft_model(model, qlora_config)\n",
    "model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_function(examples):\n",
    "    # Tokenize the inputs and targets\n",
    "    inputs = examples[\"question\"]\n",
    "    targets = examples[\"answer\"]\n",
    "    \n",
    "    # Tokenize inputs and targets separately, keeping all relevant fields\n",
    "    model_inputs = tokenizer(inputs, max_length=512, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    labels = tokenizer(targets, max_length=128, truncation=True, padding=\"max_length\", return_tensors=\"pt\")\n",
    "    \n",
    "    # Include attention_mask in model_inputs and set labels\n",
    "    model_inputs[\"labels\"] = labels[\"input_ids\"]\n",
    "    \n",
    "    return {\n",
    "        \"input_ids\": model_inputs[\"input_ids\"],\n",
    "        \"attention_mask\": model_inputs[\"attention_mask\"],\n",
    "        \"labels\": model_inputs[\"labels\"]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07bd11858e7345c39d7d5d1020f92fb8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/7473 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "acf9169f0c0140a294b9620c03ae483a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/1319 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Tokenize and remove unnecessary columns\n",
    "train_data = train.map(preprocess_function, batched=True, remove_columns=[\"question\", \"answer\"])\n",
    "eval_data = eval.map(preprocess_function, batched=True, remove_columns=[\"question\", \"answer\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data collator\n",
    "label_pad_token_id = -100\n",
    "data_collator = DataCollatorForSeq2Seq(\n",
    "    tokenizer,\n",
    "    model=model,\n",
    "    label_pad_token_id=label_pad_token_id,\n",
    "    pad_to_multiple_of=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args = Seq2SeqTrainingArguments(\n",
    "    output_dir=\"./t5-small-gsm8k-socratic-qlora\",\n",
    "    eval_strategy=\"epoch\",\n",
    "    learning_rate=5e-4,\n",
    "    per_device_train_batch_size=2,  # reduce batch size\n",
    "    per_device_eval_batch_size=2,\n",
    "    num_train_epochs=3,\n",
    "    weight_decay=0.01,\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    logging_steps=10,\n",
    "    load_best_model_at_end=True,\n",
    "    remove_unused_columns=False,\n",
    "    fp16=True  # enable mixed precision if available\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Trainer\n",
    "trainer = Seq2SeqTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_data,\n",
    "    eval_dataset=eval_data,\n",
    "    data_collator=data_collator,\n",
    ")\n",
    "model.config.use_cache = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='11211' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [    3/11211 00:00 < 38:44, 4.82 it/s, Epoch 0.00/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "TrainOutput(global_step=11211, training_loss=1.648648853848976, metrics={'train_runtime': 2242.8066, 'train_samples_per_second': 9.996, 'train_steps_per_second': 4.999, 'total_flos': 1.3713159750156288e+16, 'train_loss': 1.648648853848976, 'epoch': 3.0})"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fine-tune the model\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('./t5-base-gsm8k-socratic-qlora/tokenizer_config.json',\n",
       " './t5-base-gsm8k-socratic-qlora/special_tokens_map.json',\n",
       " './t5-base-gsm8k-socratic-qlora/spiece.model',\n",
       " './t5-base-gsm8k-socratic-qlora/added_tokens.json',\n",
       " './t5-base-gsm8k-socratic-qlora/tokenizer.json')"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.save_pretrained(\"./t5-base-gsm8k-socratic-qlora\")\n",
    "tokenizer.save_pretrained(\"./t5-base-gsm8k-socratic-qlora\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='3' max='660' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [  3/660 00:00 < 00:33, 19.47 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Perplexity: 2.375446081161499\n"
     ]
    }
   ],
   "source": [
    "# Evaluation\n",
    "eval_results = trainer.evaluate()\n",
    "print(f\"Perplexity: {torch.exp(torch.tensor(eval_results['eval_loss']))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model and tokenizer from the saved directory\n",
    "model_path = tokenizer_path = \"./t5-base-gsm8k-socratic-qlora\"\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from transformers import pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the T5-small model and tokenizer\n",
    "base_tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "base_model = AutoModelForSeq2SeqLM.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "qlora_tokenizer = AutoTokenizer.from_pretrained(tokenizer_path)\n",
    "qlora_model = AutoModelForSeq2SeqLM.from_pretrained(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from evaluation import *\n",
    "evaluator = Evaluation(qlora_model, qlora_tokenizer, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROUGE results: {'rouge1': np.float64(0.23618406633267777), 'rouge2': np.float64(0.14452999341987302), 'rougeL': np.float64(0.21073281428230745), 'rougeLsum': np.float64(0.22943474210107465)}\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on ROUGE metrics\n",
    "rouge_results = evaluator.evaluate_rouge(eval)\n",
    "print(\"ROUGE results:\", rouge_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You seem to be using the pipelines sequentially on GPU. In order to maximize efficiency please use a dataset\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.06%\n"
     ]
    }
   ],
   "source": [
    "accuracy_base = evaluator.evaluate_accuracy(eval, base_model, base_tokenizer)\n",
    "print(f\"Accuracy: {accuracy_base:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.99%\n"
     ]
    }
   ],
   "source": [
    "accuracy = evaluator.evaluate_accuracy(eval, qlora_model, qlora_tokenizer)\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using Chain-Of-Thoughts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate using Chain-of-Thought (CoT) and few-shot learning\n",
    "# accuracy_cot_few_shot = evaluator.evaluate_with_cot(eval)\n",
    "# print(f\"Accuracy: {accuracy_cot_few_shot:.2f}%\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Semantic Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average semantic similarity: 75.96%\n"
     ]
    }
   ],
   "source": [
    "res = evaluator.evaluate_semantic_similarity(eval)\n",
    "print(f\"Average semantic similarity: {(res*100):.2f}%\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proj",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
